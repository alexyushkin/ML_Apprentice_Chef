{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collaborative-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the notebook prints the models comparing table as an output \n",
    "# only. If it is necessary to check preliminary print output, change value \n",
    "# of this parameter to True.\n",
    "show_intermediate_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "devoted-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show print output which was used for analysis, feature engineering and\n",
    "# regression adjustments, and is not very useful in terms of explanation, \n",
    "# but can be used for future adjustments and development (activation will\n",
    "# significantly increase the time of runnig, so is NOT RECOMMENDED)\n",
    "show_dev_output = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worldwide-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library to control time of running\n",
    "import time\n",
    "\n",
    "# activating timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colored-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "# data processing and analysis essentials\n",
    "import pandas as pd\n",
    "\n",
    "# essential graphical output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# enhanced graphical output\n",
    "import seaborn as sns\n",
    "\n",
    "# mathematical essentials\n",
    "import numpy as np \n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# k nearest neighbors for regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# auc score\n",
    "from sklearn.metrics import roc_auc_score            \n",
    "\n",
    "# KNN for classification\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "\n",
    "# standard scaler\n",
    "from sklearn.preprocessing import StandardScaler     \n",
    "  \n",
    "# customizable scorer\n",
    "from sklearn.metrics import make_scorer              \n",
    "\n",
    "# hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV     \n",
    "\n",
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# classification trees\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# exports graphics\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# saves objects in memory\n",
    "from six import StringIO\n",
    "\n",
    "# displays on frontend\n",
    "from IPython.display import Image \n",
    "\n",
    "# interprets dot objects\n",
    "import pydotplus                                     \n",
    "\n",
    "# random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# deactivating warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spiritual-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting visualization style \n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# setting palette\n",
    "my_palette = sns.color_palette(\"gist_earth\")\n",
    "sns.set_palette(my_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precious-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting pandas output option\n",
    "pd.options.display.max_columns = 150\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "requested-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a path to the file with data\n",
    "file = './datasets/Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "# reading the file\n",
    "data = pd.read_excel(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "generic-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### creating features from object values ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## creating features from EMAIL ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adequate-spotlight",
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "# email domain types\n",
    "\n",
    "# domain names of professional emails\n",
    "domain_professional = [\n",
    "    '@mmm.com', '@amex.com,' '@apple.com', '@boeing.com', \n",
    "    '@caterpillar.com', '@chevron.com', '@cisco.com', \n",
    "    '@cocacola.com','@disney.com', '@dupont.com', \n",
    "    '@exxon.com', '@ge.org', '@goldmansacs.com', \n",
    "    '@homedepot.com', '@ibm.com', '@intel.com', '@jnj.com', \n",
    "    '@jpmorgan.com', '@mcdonalds.com', '@merck.com', \n",
    "    '@microsoft.com', '@nike.com', '@pfizer.com', \n",
    "    '@pg.com', '@travelers.com', '@unitedtech.com', \n",
    "    '@unitedhealth.com', '@verizon.com', '@visa.com', \n",
    "    '@walmart.com', '@amex.com', '@apple.com']\n",
    "\n",
    "# domain names of personal emails\n",
    "domain_personal = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "# domain names of junk emails\n",
    "domain_junk = [\n",
    "    '@me.com', '@aol.com', '@hotmail.com', '@live.com', \n",
    "    '@msn.com', '@passport.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cordless-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders of dummy variables for domain types\n",
    "data['domain_personal'] = 0\n",
    "data['domain_professional'] = 0\n",
    "data['domain_junk'] = 0\n",
    "\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in data.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@' and add '@' at the beginning\n",
    "    domain = '@' + data.loc[index, 'EMAIL'].split(sep='@')[1]\n",
    "    \n",
    "    # filling out personal domain column\n",
    "    if domain in domain_personal:\n",
    "        data.loc[index, 'domain_personal'] = 1\n",
    "\n",
    "    # filling out professional domain column\n",
    "    elif domain in domain_professional:\n",
    "        data.loc[index, 'domain_professional'] = 1\n",
    "\n",
    "    # filling out junk domain column\n",
    "    elif domain in domain_junk:\n",
    "        data.loc[index, 'domain_junk'] = 1\n",
    "    \n",
    "    # print message if a domain is missing in all lists\n",
    "    else:\n",
    "        print('Unknown')\n",
    "\n",
    "        \n",
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # checking results\n",
    "    print(f\"\"\"\n",
    "domain_personal {data['domain_personal'].sum():12}\n",
    "domain_professional {data['domain_professional'].sum():8}\n",
    "domain_junk {data['domain_junk'].sum():16}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "premium-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### creating features from FIRST_NAME ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expensive-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the results of gender guesser running from part I\n",
    "genders_initial = [\n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', \n",
    "    'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'male', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'male', 'unknown', 'unknown', 'mostly_male', 'female', 'unknown', 'male', \n",
    "    'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'mostly_male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'male', 'male', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'male', 'male', 'male', 'female', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', \n",
    "    'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', 'female', \n",
    "    'female', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'female', 'unknown', 'andy', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'mostly_male', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', \n",
    "    'unknown', 'mostly_male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'female', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'male', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'male', \n",
    "    'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'mostly_male', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', \n",
    "    'andy', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', \n",
    "    'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'andy', 'male', 'unknown', 'unknown', 'male', 'male', \n",
    "    'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', 'female', \n",
    "    'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'female', \n",
    "    'male', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'mostly_female', 'mostly_female', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'female', 'female', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'male', 'female', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'male', 'male', 'male', 'male', 'male', 'male', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'mostly_female', 'mostly_female', 'unknown', 'male', 'unknown', \n",
    "    'female', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'male', 'male', 'unknown', 'female', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'male', 'male', 'male', 'male', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'male', 'male', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'unknown', 'male', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', \n",
    "    'male', 'mostly_male', 'male', 'male', 'male', 'male', 'mostly_male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'andy', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'female', 'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'male', 'mostly_male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'female', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', \n",
    "    'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', 'male', \n",
    "    'unknown', 'male', 'female', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'female', 'female', 'male', 'male', 'female', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', \n",
    "    'male', 'andy', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'female', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'male', 'male', 'male', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'male', 'male', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'female', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'female', 'unknown', 'unknown', 'male', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'male', 'male', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'female', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'male', 'male', 'unknown', 'male', 'male', 'male', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'male', 'male', 'unknown', 'male', \n",
    "    'unknown', 'mostly_female', 'male', 'unknown', 'unknown', 'female', 'male', \n",
    "    'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'female', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_female', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'male', 'male', \n",
    "    'female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'unknown', 'mostly_male', 'mostly_male', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'male', 'unknown', \n",
    "    'female', 'male', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'male', 'unknown', 'unknown', 'male', 'male', 'male', 'mostly_male', \n",
    "    'unknown', 'unknown', 'male', 'andy', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'mostly_female', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', 'female', \n",
    "    'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', 'female', \n",
    "    'unknown', 'unknown', 'mostly_female', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'female', 'male', \n",
    "    'female', 'mostly_female', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'mostly_female', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'female', 'female', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'female', 'female', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'mostly_female', 'male', 'unknown', 'unknown', 'female', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'mostly_female', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'mostly_female', \n",
    "    'female', 'female', 'male', 'male', 'male', 'unknown', 'unknown', \n",
    "    'mostly_female', 'unknown', 'unknown', 'male', 'male', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', \n",
    "    'unknown', 'female', 'unknown', 'male', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'female', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'male', 'female', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'andy', 'unknown', 'unknown', 'male', 'male', 'male', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'mostly_male', 'male', 'male', \n",
    "    'unknown', 'male', 'unknown', 'mostly_male', 'female', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'male', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'mostly_male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'female', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'mostly_female', 'unknown', 'unknown', 'unknown', 'female', 'female', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'male', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'mostly_female', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'unknown', 'unknown', 'male', 'male', 'unknown', 'female', 'unknown', \n",
    "    'unknown', 'male', 'male', 'male', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'mostly_female', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'andy', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'female', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'male', 'unknown', \n",
    "    'unknown', 'unknown', 'male', 'mostly_male', 'unknown', 'male', 'male', \n",
    "    'unknown', 'unknown', 'male', 'male', 'male', 'male', 'andy', 'unknown', \n",
    "    'unknown', 'female', 'unknown', 'unknown', 'male', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'male', 'female', 'female', 'unknown', \n",
    "    'unknown', 'male', 'unknown', 'unknown', 'unknown', 'unknown', 'male', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', 'unknown', \n",
    "    'male', 'unknown', 'unknown', 'female', 'unknown', 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fitted-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of gender guesses into a series and add to the data \n",
    "# dataframe\n",
    "data['gender_guess'] = pd.Series(genders_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cooperative-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing mostly_male by male\n",
    "data.loc[:, 'gender_guess'][data['gender_guess'] == 'mostly_male'] = 'male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aquatic-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing mostly_female by female\n",
    "data.loc[:, 'gender_guess'][data['gender_guess'] == 'mostly_female'] = \\\n",
    "                                                                     'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "heard-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing andy by unknown\n",
    "data.loc[:, 'gender_guess'][data['gender_guess'] == 'andy'] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "brief-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy variables from the gender_guess column\n",
    "data = data.join(pd.get_dummies(data['gender_guess'], prefix = 'gender'))\n",
    "\n",
    "# dropping the gender_guess column\n",
    "data.drop('gender_guess', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bulgarian-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating new variables as a result of visualisations analysis in part I ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "framed-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# creating variable from PRODUCT_CATEGORIES_VIEWED ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "czech-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dummy variable for PRODUCT_CATEGORIES_VIEWED <= 3\n",
    "data['product_categories_viewed_up_to_3'] = \\\n",
    "    data['PRODUCT_CATEGORIES_VIEWED'].apply(lambda x: 1 if x <= 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "french-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dummy variable for PRODUCT_CATEGORIES_VIEWED > 3 and <= 9\n",
    "data['product_categories_viewed_4_9'] = \\\n",
    "    data['PRODUCT_CATEGORIES_VIEWED'].apply(lambda x: 1 if x <= 9 and \n",
    "                                                                x > 3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "differential-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dummy variable for PRODUCT_CATEGORIES_VIEWED > 9\n",
    "data['product_categories_viewed_10plus'] = \\\n",
    "    data['PRODUCT_CATEGORIES_VIEWED'].apply(lambda x: 1 if x > 9 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "greenhouse-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## log(x + 1) transforming count variables ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "addressed-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_LATE_DELIVERIES'] = np.log1p(data['LATE_DELIVERIES'])\n",
    "\n",
    "data['log_TOTAL_MEALS_ORDERED'] = np.log1p(data['TOTAL_MEALS_ORDERED'])\n",
    "\n",
    "data['log_TOTAL_PHOTOS_VIEWED'] = np.log1p(data['TOTAL_PHOTOS_VIEWED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bright-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### additional features engineering #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ultimate-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total logins\n",
    "data['total_logins'] = data['PC_LOGINS'] + data['MOBILE_LOGINS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "known-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we know from the dictionary, LARGEST_ORDER_SIZE in reality stands for \n",
    "# average number of meals ordered per customer. This raises questions,\n",
    "# but at least the following division operation might make sense\n",
    "data['term'] = data['TOTAL_MEALS_ORDERED'] / (data['LARGEST_ORDER_SIZE'] + 1)\n",
    "\n",
    "# logarithm transformed parameter\n",
    "data['log_term'] = np.log1p(data['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "equivalent-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is necessary to prove the age to get alcohol beverages, customers \n",
    "# who want to purchase alcohol have to submit a picture of a government-issued \n",
    "# ID card, so we can assume that family names of people who submitted pictures\n",
    "# of their IDs are known\n",
    "\n",
    "# to filter customers who did not submitted their IDs we will take into \n",
    "# account customers with missing family names or those ones whose first and\n",
    "# last names are equal\n",
    "\n",
    "# we will also tale into accout those customers whose family names don't \n",
    "# appear to be real family names, that is start with 'the' or 'of'\n",
    "\n",
    "# replacing NaNs with empty strings\n",
    "data['FAMILY_NAME'].fillna('', inplace=True)\n",
    "\n",
    "# creating the column with a feature of no last name and filling it with 0s\n",
    "data['no_family_name'] = 0\n",
    "# filling the column with 1s for customers with no family name or customers \n",
    "# whose first and last names are equal\n",
    "data.loc[:, 'no_family_name'][data['FAMILY_NAME'] == ''] = 1\n",
    "data.loc[:, 'no_family_name'][data['FIRST_NAME'] == data['FAMILY_NAME']] = 1\n",
    "\n",
    "# filling the column for customers whose family names start with 'the' or 'of'\n",
    "for i in range(0, len(data['FAMILY_NAME'])):\n",
    "    try:\n",
    "        if data.loc[i, 'FAMILY_NAME'].split()[0] == 'the' \\\n",
    "                            or data.loc[i, 'FAMILY_NAME'].split()[0] == 'of':\n",
    "            data.loc[i, 'no_family_name'] = 1\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceramic-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating features of quantity of words and letters in customers' names\n",
    "# creating the columns and filling them with zeros\n",
    "data['name_length_words'] = 0\n",
    "data['name_length_letters'] = 0\n",
    "\n",
    "# filling the columns with quantity of words and letters respectively\n",
    "try:\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i, 'name_length_words'] = \\\n",
    "            len(data.loc[i, 'FIRST_NAME'].split()) \\\n",
    "                    + len(data.loc[i, 'FAMILY_NAME'].split())\n",
    "        data.loc[i, 'name_length_letters'] = \\\n",
    "            len(data.loc[i, 'FIRST_NAME']) + len(data.loc[i, 'FAMILY_NAME'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "simplified-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature of family names frequency\n",
    "family_dict = dict(data['FAMILY_NAME'].value_counts())\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data.loc[i, 'family_freq'] = family_dict[data.loc[i, 'FAMILY_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "compressed-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating columns for 25th, 50th, and 75th percentiles of revenue\n",
    "percentiles = np.percentile(data['REVENUE'], [25, 50, 75])\n",
    "\n",
    "data['rev_perc_25'] = data['REVENUE'].\\\n",
    "    apply(lambda x: 1 if x <= percentiles[0] else 0)\n",
    "\n",
    "data['rev_perc_50'] = data['REVENUE'].\\\n",
    "    apply(lambda x: 1 if x > percentiles[0] and x <= percentiles[1] else 0)\n",
    "\n",
    "data['rev_perc_75'] = data['REVENUE'].\\\n",
    "    apply(lambda x: 1 if x > percentiles[1] and x <= percentiles[2] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "primary-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature of contacts with customer service frequence in relation \n",
    "# with total quantity of orders\n",
    "data['contacts_freq'] = data['CONTACTS_W_CUSTOMER_SERVICE'] \\\n",
    "                                            / data['TOTAL_MEALS_ORDERED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "reserved-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature of average photos viewed per session\n",
    "data['avg_photos_per_visit'] = data['TOTAL_PHOTOS_VIEWED'] \\\n",
    "                                            / data['total_logins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "hispanic-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature of total clicks\n",
    "data['total_clicks'] = data['AVG_CLICKS_PER_VISIT'] * data['total_logins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "exterior-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a feature of total time spent on the company's website\n",
    "data['total_time_on_site'] = data['AVG_TIME_PER_SITE_VISIT'] \\\n",
    "                                            * data['total_logins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "communist-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking results\n",
    "# data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "major-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### creating a list of all explanatory variables #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "victorian-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = pd.Series(data.columns)\n",
    "features_all = features_all.drop([1, 2, 3, 4, 5]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efficient-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### checking correlation coefficients #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cleared-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # creating a correlation matrix\n",
    "    df_corr = data.corr().round(2)\n",
    "\n",
    "    # printing correlations with log_REVENUE\n",
    "    print(df_corr.loc['CROSS_SELL_SUCCESS']\\\n",
    "          [abs(df_corr.loc['CROSS_SELL_SUCCESS']) > 0.00]\\\n",
    "                                                .sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hearing-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    feat_corr = list(df_corr.loc['CROSS_SELL_SUCCESS']\\\n",
    "          [((abs(df_corr.loc['CROSS_SELL_SUCCESS']) > 0.069) & \\\n",
    "            (df_corr.index != 'CROSS_SELL_SUCCESS'))].index)\n",
    "    print(feat_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "confidential-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# building and adjusting a models in scikit-learn ################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bibliographic-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# preparing data #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "wicked-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    "'final': \n",
    "            ['domain_junk',\n",
    "             'no_family_name',\n",
    "             'WEEKLY_PLAN',\n",
    "             'AVG_PREP_VID_TIME',\n",
    "             'CANCELLATIONS_BEFORE_NOON',\n",
    "             'total_time_on_site',\n",
    "             'LARGEST_ORDER_SIZE',\n",
    "             'log_term',\n",
    "             'gender_unknown',\n",
    "             'avg_photos_per_visit',\n",
    "             'log_LATE_DELIVERIES',\n",
    "             'contacts_freq',\n",
    "             'product_categories_viewed_4_9',\n",
    "             'EARLY_DELIVERIES',\n",
    "             'total_logins',\n",
    "             'rev_perc_50',\n",
    "             'log_TOTAL_PHOTOS_VIEWED',\n",
    "             'MOBILE_NUMBER',\n",
    "             'log_TOTAL_MEALS_ORDERED',\n",
    "             'CANCELLATIONS_AFTER_NOON',\n",
    "             'MOBILE_LOGINS',\n",
    "             'gender_female',\n",
    "             'REFRIGERATED_LOCKER',\n",
    "             'domain_personal',\n",
    "             'REVENUE',\n",
    "             'total_clicks',\n",
    "             'TASTES_AND_PREFERENCES',\n",
    "             'name_length_words',\n",
    "             'family_freq',\n",
    "             'name_length_letters'], \n",
    "    \n",
    "'sig_dt4': \n",
    "            ['domain_junk',\n",
    "             'no_family_name',\n",
    "             'WEEKLY_PLAN',\n",
    "             'AVG_PREP_VID_TIME',\n",
    "             'CANCELLATIONS_BEFORE_NOON',\n",
    "             'total_time_on_site',\n",
    "             'LARGEST_ORDER_SIZE',\n",
    "             'log_term',\n",
    "             'gender_unknown',\n",
    "             'avg_photos_per_visit',\n",
    "             'log_LATE_DELIVERIES',\n",
    "             'contacts_freq',\n",
    "             'product_categories_viewed_4_9',\n",
    "             'EARLY_DELIVERIES',\n",
    "             'total_logins',\n",
    "             'rev_perc_50',\n",
    "             'log_TOTAL_PHOTOS_VIEWED',\n",
    "             'MOBILE_NUMBER',\n",
    "             'log_TOTAL_MEALS_ORDERED',\n",
    "             'CANCELLATIONS_AFTER_NOON',\n",
    "             'MOBILE_LOGINS',\n",
    "             'gender_female',\n",
    "             'REFRIGERATED_LOCKER',\n",
    "             'domain_personal',\n",
    "             'REVENUE',\n",
    "             'total_clicks',\n",
    "             'TASTES_AND_PREFERENCES'], \n",
    "    \n",
    "'007_plus_l':\n",
    "            ['MOBILE_NUMBER',\n",
    "             'TASTES_AND_PREFERENCES',\n",
    "             'REFRIGERATED_LOCKER',\n",
    "             'domain_professional',\n",
    "             'domain_junk',\n",
    "             'gender_female',\n",
    "             'gender_male',\n",
    "             'log_CANCELLATIONS_BEFORE_NOON',\n",
    "             'log_total_cancellations',\n",
    "             'cancelled_before_noon',\n",
    "             'cancelled_orders',\n",
    "             'no_family_name'], \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mechanical-insurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the full dataset\n",
    "X_data = data[features_all]\n",
    "y_data = data.loc[:, 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# subsetting\n",
    "x_data = X_data.loc[:, candidate_dict['final']] \n",
    "\n",
    "# train/test splitting of the subset\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "                                                    x_data,\n",
    "                                                    y_data,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=219,\n",
    "                                                    stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aging-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fitting the data\n",
    "scaler.fit(x_data)\n",
    "\n",
    "# transforming the data\n",
    "X_scaled = scaler.transform(x_data)\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_data_scaled = pd.DataFrame(X_scaled)\n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train, y_test = train_test_split(\n",
    "                                                        x_data_scaled,\n",
    "                                                        y_data,\n",
    "                                                        test_size=0.25,\n",
    "                                                        random_state=219,\n",
    "                                                        stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "brazilian-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Logistic Regression #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "congressional-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a logistic regression model\n",
    "lr = LogisticRegression(solver='lbfgs',\n",
    "                        C=1.0,\n",
    "                        warm_start=False,\n",
    "                        max_iter=100,\n",
    "                        random_state=219)\n",
    "\n",
    "# fitting the training data\n",
    "lr_fit = lr.fit(x_train_scaled, y_train)\n",
    "\n",
    "# predicting based on the testing set\n",
    "lr_pred = lr_fit.predict(x_test_scaled)\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_train_score = lr_fit.score(x_train_scaled, y_train).round(4) \n",
    "lr_test_score = lr_fit.score(x_test_scaled, y_test).round(4)   \n",
    "lr_auc = roc_auc_score(y_true=y_test, y_score=lr_pred).round(4) \n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', lr_train_score)\n",
    "    print('Testing ACCURACY :', lr_test_score)\n",
    "    print('AUC Score        :', lr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "accurate-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tn, \\\n",
    "lr_fp, \\\n",
    "lr_fn, \\\n",
    "lr_tp = confusion_matrix(y_true=y_test, y_pred=lr_pred).ravel()\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing each result one-by-one\n",
    "    print(f\"\"\"\n",
    "True Negatives : {lr_tn}\n",
    "False Positives: {lr_fp}\n",
    "False Negatives: {lr_fn}\n",
    "True Positives : {lr_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "guilty-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "C_space = [5.1]\n",
    "warm_start_space = [True]\n",
    "solver_space = ['lbfgs']\n",
    "# C_space = pd.np.arange(1.4, 5.5, 0.1)\n",
    "# warm_start_space = [True, False]\n",
    "# solver_space = ['newton-cg', 'sag', 'lbfgs']\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'C': C_space,\n",
    "              'warm_start': warm_start_space,\n",
    "              'solver': solver_space}\n",
    "\n",
    "# instantiating the model object without hyperparameters\n",
    "lr_tuned = LogisticRegression(random_state=219,\n",
    "                              max_iter=1000)\n",
    "\n",
    "# GridSearchCV object\n",
    "lr_tuned_cv_scaled = GridSearchCV(estimator=lr_tuned, \n",
    "                                  param_grid=param_grid, \n",
    "                                  cv=3,         \n",
    "                                  n_jobs=-1,\n",
    "                                  scoring=make_scorer(\n",
    "                                                      roc_auc_score,\n",
    "                                                      needs_threshold=False)) \n",
    "\n",
    "# fitting to the full dataset\n",
    "lr_tuned_cv_scaled.fit(x_data_scaled, y_data)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # printing the optimal parameters and best score\n",
    "    print(\"Tuned Parameters:\", lr_tuned_cv_scaled.best_params_)\n",
    "    print(\"Tuned CV AUC    :\", lr_tuned_cv_scaled.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "worldwide-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # checking the best estimator for the model\n",
    "    print(lr_tuned_cv_scaled.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ongoing-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# instantiating a logistic regression model with tuned values\n",
    "lr_tuned = lr_tuned_cv_scaled.best_estimator_\n",
    "\n",
    "# predicting based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test_scaled)\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train_scaled, y_train).round(4) \n",
    "lr_tuned_test_score = lr_tuned.score(x_test_scaled, y_test).round(4) \n",
    "lr_tuned_auc = roc_auc_score(y_true=y_test, y_score=lr_tuned_pred).round(4)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', lr_tuned_train_score)\n",
    "    print('Testing ACCURACY :', lr_tuned_test_score)\n",
    "    print('AUC Score        :', lr_tuned_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "scheduled-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true=y_test, y_pred=lr_tuned_pred).ravel()\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing each result one-by-one\n",
    "    print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "soviet-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_adjusting(model, x_train, y_train, x_test, y_test, threshold, \n",
    "                    print_output=False):\n",
    "    \"\"\"\n",
    "    Changes the threshold of classification model from 50/50 to the given \n",
    "    value, computes and returns training and testing scores, roc-auc metric, \n",
    "    and confusion matrix parameters, if necessary, prints scores and confusion\n",
    "    matrix parameters. \n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model        : model object, classification model\n",
    "    x_train      : dataframe, explanatory variable training data\n",
    "    y_train      : series, response variable training data\n",
    "    x_test       : dataframe, explanatory variable testing data\n",
    "    y_train      : series, response variable testing data\n",
    "    threshold    : float, the threshold which the function uses to predict \n",
    "                   classes 0 and 1\n",
    "    print_output : bool, if the result should be printed, default False\n",
    "    \"\"\"\n",
    "\n",
    "    # getting probabilities for train subset\n",
    "    pred_proba_train = model.predict_proba(x_train)\n",
    "\n",
    "    # placeholder for the list of predictions\n",
    "    predictions_train = []\n",
    "    # predicting for train subset\n",
    "    for prob in pred_proba_train[:, 1]:\n",
    "        if prob >= threshold:\n",
    "            predictions_train.append(1)\n",
    "        else:\n",
    "            predictions_train.append(0)\n",
    "\n",
    "\n",
    "    # getting probabilities for test subset\n",
    "    pred_proba_test = model.predict_proba(x_test)\n",
    "\n",
    "    # placeholder for the list of predictions\n",
    "    predictions_test = []\n",
    "    # predicting for test subset\n",
    "    for prob in pred_proba_test[:, 1]:\n",
    "        if prob >= threshold:\n",
    "            predictions_test.append(1)\n",
    "        else:\n",
    "            predictions_test.append(0)\n",
    "\n",
    "\n",
    "    # unpacking the confusion matrix for train subset\n",
    "    tn_train, \\\n",
    "    fp_train, \\\n",
    "    fn_train, \\\n",
    "    tp_train = confusion_matrix(y_true=y_train, \n",
    "                                y_pred=predictions_train).ravel()\n",
    "\n",
    "    # unpacking the confusion matrix for test subset\n",
    "    tn_test, \\\n",
    "    fp_test, \\\n",
    "    fn_test, \\\n",
    "    tp_test = confusion_matrix(y_true=y_test, \n",
    "                               y_pred=predictions_test).ravel()\n",
    "\n",
    "\n",
    "    # saving scoring results\n",
    "    # train_score = round((tn_train + tp_train) \\\n",
    "    #                   / (tn_train + tp_train + fp_train + fn_train), 4)\n",
    "    train_score = model.score(x_train, predictions_train).round(4)\n",
    "\n",
    "    # test_score = round((tn_test + tp_test) \\\n",
    "    #                  / (tn_test + tp_test + fp_test + fn_test), 4)\n",
    "    test_score = model.score(x_test, predictions_test).round(4)\n",
    "\n",
    "    auc = roc_auc_score(y_true=y_test, y_score=predictions_test).round(4)\n",
    "\n",
    "\n",
    "    # preventing print output if it is not needed\n",
    "    if print_output:\n",
    "\n",
    "        # printing scores\n",
    "        print('Training ACCURACY:', train_score)\n",
    "        print('Testing ACCURACY :', test_score)\n",
    "        print('AUC Score        :', auc)\n",
    "\n",
    "        # printing values of confusion matrix\n",
    "        print(f\"\"\"\n",
    "True Negatives : {tn_test}\n",
    "False Positives: {fp_test}\n",
    "False Negatives: {fn_test}\n",
    "True Positives : {tp_test}\n",
    "    \"\"\")\n",
    "        \n",
    "    return train_score, test_score, auc, tn_test, fp_test, fn_test, tp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "located-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the model\n",
    "    \n",
    "# setting threshold\n",
    "threshold = 0.713\n",
    "\n",
    "# calling the function and getting accuracy and auc scores as well as \n",
    "# confusion matrix parameters\n",
    "adj_lr_train_score, \\\n",
    "adj_lr_test_score, \\\n",
    "adj_lr_auc, \\\n",
    "adj_lr_tn_test, \\\n",
    "adj_lr_fp_test, \\\n",
    "adj_lr_fn_test, \\\n",
    "adj_lr_tp_test = model_adjusting(lr_tuned, \n",
    "                                 x_train_scaled, y_train, \n",
    "                                 x_test_scaled, y_test, threshold, \n",
    "                                 print_output=show_intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "blond-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Classification Trees ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "moving-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importances function\n",
    "def plot_feature_importances(model, train, export=False):\n",
    "    \"\"\"\n",
    "    Plots the importance of features from a CART model.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    model  : CART model\n",
    "    train  : explanatory variable training data\n",
    "    export : whether or not to export as a .png image, default False\n",
    "    \"\"\"\n",
    "    \n",
    "    # declaring the number\n",
    "    n_features = x_train.shape[1]\n",
    "    \n",
    "    # setting plot window\n",
    "    fig, ax = plt.subplots(figsize=(12,9))\n",
    "    \n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(pd.np.arange(n_features), train.columns)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    \n",
    "    if export == True:\n",
    "        plt.savefig('Tree_Leaf_50_Feature_Importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "skilled-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing running if it is not needed\n",
    "if show_dev_output:\n",
    "\n",
    "    # instantiating a classification tree object\n",
    "    dt = DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "    # fitting the training data\n",
    "    dt_fit = dt.fit(x_train, y_train)\n",
    "\n",
    "    # predicting on new data\n",
    "    dt_pred = dt_fit.predict(x_test)\n",
    "\n",
    "    # saving scoring data for future use\n",
    "    dt_train_score = dt_fit.score(x_train, y_train).round(4) \n",
    "    dt_test_score = dt_fit.score(x_test, y_test).round(4)\n",
    "    dt_auc_score = roc_auc_score(y_true=y_test, y_score=dt_pred).round(4) \n",
    "\n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', dt_train_score)\n",
    "    print('Testing ACCURACY :', dt_test_score)\n",
    "    print('AUC Score        :', dt_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "nutritional-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # instantiating a classification tree object\n",
    "    dt_scaled = DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "    # fitting the training data\n",
    "    dt_fit_scaled = dt_scaled.fit(x_train_scaled, y_train)\n",
    "\n",
    "    # predicting on new data\n",
    "    dt_pred_scaled = dt_fit_scaled.predict(x_test_scaled)\n",
    "\n",
    "    # saving scoring data for future use\n",
    "    dt_scaled_train_score = dt_fit_scaled.\\\n",
    "                                    score(x_train_scaled, y_train).round(4) \n",
    "    dt_scaled_test_score = dt_fit_scaled.\\\n",
    "                                    score(x_test_scaled, y_test).round(4)   \n",
    "    dt_scaled_auc_score = roc_auc_score(y_true=y_test,\n",
    "                                        y_score=dt_pred_scaled).round(4)\n",
    "\n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', dt_scaled_train_score)\n",
    "    print('Testing ACCURACY :', dt_scaled_test_score)\n",
    "    print('AUC Score        :', dt_scaled_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "scheduled-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "\n",
    "    # plotting feature importance\n",
    "    plot_feature_importances(dt_fit,\n",
    "                             train=x_train,\n",
    "                             export=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "leading-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this chunk of code might be used to get features in descending order \n",
    "# # of their significance\n",
    "# df = pd.DataFrame(zip(x_train.columns, \n",
    "#                       full_tree_fit.feature_importances_)).\\\n",
    "#                           sort_values(1, ascending=False)\n",
    "# sig_dt = df[df[1]>0][0].to_list()\n",
    "# sig_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "municipal-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "criterion = [\"gini\"]\n",
    "splitter = [\"best\"]\n",
    "max_depth = [5]\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [20]\n",
    "max_features = [None]\n",
    "class_weight = ['balanced']\n",
    "min_weight_fraction_leaf = [0.0]\n",
    "max_leaf_nodes = [None]\n",
    "min_impurity_decrease = [0.0]\n",
    "ccp_alpha = [0.0]\n",
    "# criterion = [\"gini\"]\n",
    "# splitter = [\"best\"]\n",
    "# max_depth = range(3, 9)\n",
    "# min_samples_split = range(2, 5)\n",
    "# min_samples_leaf = range(15, 31)\n",
    "# max_features = [None]\n",
    "# class_weight = ['balanced']\n",
    "# min_weight_fraction_leaf = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "# max_leaf_nodes = [None]\n",
    "# min_impurity_decrease = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "# ccp_alpha = [0.0, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion': criterion,\n",
    "              'splitter': splitter,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "              'min_samples_leaf': min_samples_leaf,\n",
    "              'max_features': max_features,\n",
    "              'class_weight': class_weight,\n",
    "              'min_weight_fraction_leaf': min_weight_fraction_leaf, \n",
    "              'max_leaf_nodes': max_leaf_nodes, \n",
    "              'min_impurity_decrease': min_impurity_decrease, \n",
    "              'ccp_alpha': ccp_alpha}\n",
    "\n",
    "# instantiating the model object without hyperparameters\n",
    "dt_tuned = DecisionTreeClassifier(random_state=219)\n",
    "\n",
    "# GridSearchCV object\n",
    "dt_tuned_cv_scaled = GridSearchCV(estimator=dt_tuned,   \n",
    "                                  param_grid=param_grid, \n",
    "                                  cv=3, \n",
    "                                  n_jobs=-1,\n",
    "                                  scoring=make_scorer(roc_auc_score,\n",
    "                                                      needs_threshold=False))\n",
    "\n",
    "# fitting to the full dataset\n",
    "dt_tuned_cv_scaled.fit(x_data_scaled, y_data)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # printing the optimal parameters and best score\n",
    "    print(\"Tuned Parameters:\", dt_tuned_cv_scaled.best_params_)\n",
    "    print(\"Tuned CV AUC    :\", dt_tuned_cv_scaled.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "defensive-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "\n",
    "    # checking the best estimator for the model\n",
    "    print(dt_tuned_cv_scaled.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "whole-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# instantiating a logistic regression model with tuned values\n",
    "dt_tuned = dt_tuned_cv_scaled.best_estimator_\n",
    "\n",
    "# predicting based on the testing set\n",
    "dt_tuned_pred = dt_tuned.predict(x_test_scaled)\n",
    "\n",
    "# saving scoring data for future use\n",
    "dt_tuned_train_score = dt_tuned.score(x_train_scaled, y_train).round(4) \n",
    "dt_tuned_test_score = dt_tuned.score(x_test_scaled, y_test).round(4)\n",
    "dt_tuned_auc = roc_auc_score(y_true=y_test, y_score=dt_tuned_pred).round(4)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', dt_tuned_train_score)\n",
    "    print('Testing ACCURACY :', dt_tuned_test_score)\n",
    "    print('AUC Score        :', dt_tuned_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "useful-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "dt_tuned_tn, \\\n",
    "dt_tuned_fp, \\\n",
    "dt_tuned_fn, \\\n",
    "dt_tuned_tp = confusion_matrix(y_true=y_test, y_pred=dt_tuned_pred).ravel()\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing each result one-by-one\n",
    "    print(f\"\"\"\n",
    "True Negatives : {dt_tuned_tn}\n",
    "False Positives: {dt_tuned_fp}\n",
    "False Negatives: {dt_tuned_fn}\n",
    "True Positives : {dt_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "peaceful-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the model\n",
    "\n",
    "# setting threshold\n",
    "threshold = 0.6\n",
    "\n",
    "# calling the function and getting accuracy and auc scores as well as \n",
    "# confusion matrix parameters\n",
    "adj_dt_train_score, \\\n",
    "adj_dt_test_score, \\\n",
    "adj_dt_auc, \\\n",
    "adj_dt_tn_test, \\\n",
    "adj_dt_fp_test, \\\n",
    "adj_dt_fn_test, \\\n",
    "adj_dt_tp_test = model_adjusting(dt_tuned, \n",
    "                                 x_train_scaled, y_train, \n",
    "                                 x_test_scaled, y_test, threshold, \n",
    "                                 print_output=show_intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "noticed-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## K-Nearest Neighbors Classification (KNN) ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "narrative-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_neighbors function\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize=True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exhaustively compute training and testing results for KNN across\n",
    "    [1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "    visualization of the results.\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    X_data        : explanatory variable data\n",
    "    y_data        : response variable\n",
    "    standardize   : whether or not to standardize the X data, default True\n",
    "    pct_test      : test size for training and validation from (0,1), \n",
    "                    default 0.25\n",
    "    seed          : random seed to be used in algorithm, default 219\n",
    "    response_type : type of neighbors algorithm to use, default 'reg'\n",
    "                    Use 'reg' for regression (KNeighborsRegressor)\n",
    "                    Use 'class' for classification (KNeighborsClassifier)\n",
    "    max_neighbors : maximum number of neighbors in exhaustive search, \n",
    "                    default 20\n",
    "    show_viz      : display or surpress k-neigbors visualization, default True\n",
    "    \"\"\"    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled = scaler.transform(X_data)\n",
    "        X_scaled_df = pd.DataFrame(X_scaled)\n",
    "        X_data = X_scaled_df\n",
    "\n",
    "    # train-test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size=pct_test,\n",
    "                                                        random_state=seed)\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "    \n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "            clf.fit(x_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "            clf.fit(x_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(x_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(x_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, \\\n",
    "                                                 label=\"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # preventing print output if it is not needed\n",
    "    if show_dev_output:\n",
    "        \n",
    "        # returning optimal number of neighbors\n",
    "        print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy)) + 1}\")\n",
    "    \n",
    "    return test_accuracy.index(max(test_accuracy)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "apart-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(x_data,\n",
    "                                  y_data,\n",
    "                                  standardize=True,\n",
    "                                  pct_test=0.25,\n",
    "                                  seed=219,\n",
    "                                  response_type='class',\n",
    "                                  max_neighbors=50,\n",
    "                                  show_viz=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "artificial-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors=opt_neighbors)\n",
    "\n",
    "# fitting the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train)\n",
    "\n",
    "# predicting based on the testing set\n",
    "knn_pred = knn_fit.predict(x_test_scaled)\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train).round(4)\n",
    "knn_test_score = knn_fit.score(x_test_scaled, y_test).round(4)\n",
    "knn_auc_score = roc_auc_score(y_true=y_test, y_score=knn_pred).round(4)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', knn_train_score)\n",
    "    print('Testing ACCURACY :', knn_test_score)\n",
    "    print('AUC Score        :', knn_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "flying-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "knn_tn, \\\n",
    "knn_fp, \\\n",
    "knn_fn, \\\n",
    "knn_tp = confusion_matrix(y_true=y_test, y_pred=knn_pred).ravel()\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing each result one-by-one\n",
    "    print(f\"\"\"\n",
    "True Negatives : {knn_tn}\n",
    "False Positives: {knn_fp}\n",
    "False Negatives: {knn_fn}\n",
    "True Positives : {knn_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "documented-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the model\n",
    "\n",
    "# setting threshold\n",
    "threshold = 0.68\n",
    "\n",
    "# calling the function and getting accuracy and auc scores as well as \n",
    "# confusion matrix parameters\n",
    "adj_knn_train_score, \\\n",
    "adj_knn_test_score, \\\n",
    "adj_knn_auc, \\\n",
    "adj_knn_tn_test, \\\n",
    "adj_knn_fp_test, \\\n",
    "adj_knn_fn_test, \\\n",
    "adj_knn_tp_test = model_adjusting(knn_fit, \n",
    "                                  x_train_scaled, y_train, \n",
    "                                  x_test_scaled, y_test, threshold, \n",
    "                                  print_output=show_intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "identical-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Random Forest (Classification) #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "anticipated-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "\n",
    "    # instantiating, fitting, predicting\n",
    "    rf = RandomForestClassifier(random_state=219, max_depth=8) \n",
    "    rf_fit = rf.fit(x_train_scaled, y_train)\n",
    "    y_pred = rf_fit.predict(x_test_scaled)\n",
    "\n",
    "    # saving scoring data\n",
    "    rf_train_score = rf_fit.score(x_train_scaled, y_train).round(4)\n",
    "    rf_test_score = rf_fit.score(x_test_scaled, y_test).round(4)\n",
    "    rf_auc_score = roc_auc_score(y_true=y_test, y_score=y_pred).round(4)\n",
    "\n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', rf_train_score)\n",
    "    print('Testing ACCURACY :', rf_test_score)\n",
    "    print('AUC Score        :', rf_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "following-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "estimator_space = pd.np.arange(850, 900, 50)\n",
    "leaf_space = pd.np.arange(1, 2, 1)\n",
    "criterion_space = ['entropy']\n",
    "bootstrap_space = [False]\n",
    "warm_start_space = [True]\n",
    "# estimator_space = pd.np.arange(100, 1100, 250)\n",
    "# leaf_space = pd.np.arange(1, 31, 10)\n",
    "# criterion_space = ['gini', 'entropy']\n",
    "# bootstrap_space = [True, False]\n",
    "# warm_start_space = [True, False]\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'n_estimators': estimator_space,\n",
    "              'min_samples_leaf': leaf_space,\n",
    "              'criterion': criterion_space,\n",
    "              'bootstrap': bootstrap_space,\n",
    "              'warm_start': warm_start_space}\n",
    "\n",
    "# instantiating the model object without hyperparameters\n",
    "forest_grid = RandomForestClassifier(random_state=219)\n",
    "\n",
    "# GridSearchCV object\n",
    "forest_cv = GridSearchCV(estimator=forest_grid,   \n",
    "                         param_grid=param_grid, \n",
    "                         cv=3, \n",
    "                         n_jobs=-1,\n",
    "                         scoring=make_scorer(\n",
    "                                             roc_auc_score,\n",
    "                                             needs_threshold=False)) \n",
    "\n",
    "# fitting to the full dataset\n",
    "forest_cv.fit(x_data, y_data)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing the optimal parameters and best score\n",
    "    print(\"Tuned Parameters:\", forest_cv.best_params_)\n",
    "    print(\"Tuned CV AUC    :\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "juvenile-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # best estimators based on RandomizedSearchCV\n",
    "    print(forest_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "nonprofit-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# instantiating with best_estimator\n",
    "forest_tuned = forest_cv.best_estimator_\n",
    "\n",
    "# predicting based on the testing set\n",
    "forest_tuned_pred = forest_tuned.predict(x_test)\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4)\n",
    "forest_tuned_test_score = forest_tuned.score(x_test, y_test).round(4)\n",
    "forest_tuned_auc = roc_auc_score(y_true=y_test,\n",
    "                                 y_score=forest_tuned_pred).round(4)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', forest_tuned_train_score)\n",
    "    print('Testing ACCURACY :', forest_tuned_test_score)\n",
    "    print('AUC Score        :', forest_tuned_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "different-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # unpacking the confusion matrix\n",
    "    tuned_rf_tn, \\\n",
    "    tuned_rf_fp, \\\n",
    "    tuned_rf_fn, \\\n",
    "    tuned_rf_tp = confusion_matrix(y_true=y_test, \n",
    "                                   y_pred=forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "    # printing each result one-by-one\n",
    "    print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "lightweight-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the model\n",
    "\n",
    "# setting threshold\n",
    "threshold = 0.46\n",
    "\n",
    "# calling the function and getting accuracy and auc scores as well as \n",
    "# confusion matrix parameters\n",
    "adj_rf_tuned_train_score, \\\n",
    "adj_rf_tuned_test_score, \\\n",
    "adj_rf_tuned_auc, \\\n",
    "adj_rf_tuned_tn_test, \\\n",
    "adj_rf_tuned_fp_test, \\\n",
    "adj_rf_tuned_fn_test, \\\n",
    "adj_rf_tuned_tp_test = \\\n",
    "                    model_adjusting(forest_tuned, \n",
    "                                    x_train_scaled, y_train, \n",
    "                                    x_test_scaled, y_test, threshold, \n",
    "                                    print_output=show_intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "hourly-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### Gradient Boosted Models (GBM) ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fuzzy-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # instantiating, fitting, predicting\n",
    "    gb = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.01,\\\n",
    "                                    random_state=219, max_depth=8)\n",
    "    gb_fit = gb.fit(x_train, y_train)\n",
    "    y_pred = gb_fit.predict(x_test)\n",
    "\n",
    "    # saving scoring data\n",
    "    gb_train_score = gb_fit.score(x_train, y_train).round(4)\n",
    "    gb_test_score = gb_fit.score(x_test, y_test).round(4)\n",
    "    gb_auc_score = roc_auc_score(y_true=y_test, y_score=y_pred).round(4)\n",
    "\n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', gb_train_score)\n",
    "    print('Testing ACCURACY :', gb_test_score)\n",
    "    print('AUC Score        :', gb_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "interracial-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # GridSearchCV\n",
    "\n",
    "    # declaring a hyperparameter space\n",
    "    learn_space = [0.1]\n",
    "    estimator_space = range(100, 150, 50)\n",
    "    depth_space = range(3, 4)\n",
    "    max_features_space = [20]\n",
    "#     learn_space = [0.001, 0.01, 0.1, 1]\n",
    "#     estimator_space = range(50, 350, 50)\n",
    "#     depth_space = range(2, 6)\n",
    "#     max_features_space = [None, 20, 30]\n",
    "\n",
    "    # creating a hyperparameter grid\n",
    "    param_grid = {'learning_rate': learn_space,\n",
    "                  'max_depth': depth_space,\n",
    "                  'n_estimators': estimator_space,\n",
    "                  'max_features': max_features_space}\n",
    "\n",
    "    # instantiating the model object without hyperparameters\n",
    "    full_gbm_grid = GradientBoostingClassifier(random_state=219)\n",
    "\n",
    "    # GridSearchCV object\n",
    "    full_gbm_cv = GridSearchCV(estimator=full_gbm_grid,\n",
    "                               param_grid=param_grid, \n",
    "                               cv=3, \n",
    "                               n_jobs=-1,\n",
    "                               scoring=make_scorer(\n",
    "                                                   roc_auc_score,\n",
    "                                                   needs_threshold=False))\n",
    "\n",
    "    # fitting to the full dataset\n",
    "    full_gbm_cv.fit(x_data, y_data)\n",
    "\n",
    "    # printing the optimal parameters and best score\n",
    "    print(\"Tuned Parameters:\", full_gbm_cv.best_params_)\n",
    "    print(\"Tuned CV AUC    :\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "prime-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # best estimators based on RandomizedSearchCV\n",
    "    print(full_gbm_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ranking-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # instantiating with best_estimator\n",
    "    gb_tuned = full_gbm_cv.best_estimator_\n",
    "\n",
    "    # predicting based on the testing set\n",
    "    gb_tuned_pred = gb_tuned.predict(x_test)\n",
    "\n",
    "    # saving scoring data\n",
    "    gb_tuned_train_score = gb_tuned.score(x_train, y_train).round(4)\n",
    "    gb_tuned_test_score = gb_tuned.score(x_test, y_test).round(4)\n",
    "    gb_tuned_auc_score = \\\n",
    "                    roc_auc_score(y_true=y_test, y_score=gb_tuned_pred).round(4)\n",
    "\n",
    "    # preventing print output if it is not needed\n",
    "    if show_intermediate_output:\n",
    "\n",
    "        # printing scoring data\n",
    "        print('Training ACCURACY:', gb_tuned_train_score)\n",
    "        print('Testing ACCURACY :', gb_tuned_test_score)\n",
    "        print('AUC Score        :', gb_tuned_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "acknowledged-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing running if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # adjusting the model\n",
    "\n",
    "    # setting threshold\n",
    "    threshold = 0.656\n",
    "\n",
    "    # calling the function and getting accuracy and auc scores as well as \n",
    "    # confusion matrix parameters\n",
    "    adj_gb_tuned_train_score, \\\n",
    "    adj_gb_tuned_test_score, \\\n",
    "    adj_gb_tuned_auc, \\\n",
    "    adj_gb_tuned_tn_test, \\\n",
    "    adj_gb_tuned_fp_test, \\\n",
    "    adj_gb_tuned_fn_test, \\\n",
    "    adj_gb_tuned_tp_test = \\\n",
    "                        model_adjusting(gb_tuned, \n",
    "                                        x_train, y_train, \n",
    "                                        x_test, y_test, threshold, \n",
    "                                        print_output=show_intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "configured-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "learn_space = [0.1, 0.11, 0.12]\n",
    "estimator_space = range(100, 150, 10)\n",
    "depth_space = range(2, 4)\n",
    "max_features_space = [18, 19, 20] \n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'learning_rate': learn_space,\n",
    "              'max_depth': depth_space,\n",
    "              'n_estimators': estimator_space,\n",
    "              'max_features': max_features_space}\n",
    "\n",
    "# instantiating the model object without hyperparameters\n",
    "full_gbm_grid = GradientBoostingClassifier(random_state=219)\n",
    "\n",
    "# GridSearchCV object\n",
    "full_gbm_cv_scaled = GridSearchCV(estimator=full_gbm_grid,\n",
    "                                 param_grid=param_grid, \n",
    "                                 cv=3, \n",
    "                                 n_jobs=-1, \n",
    "                                 scoring=make_scorer(\n",
    "                                                     roc_auc_score,\n",
    "                                                     needs_threshold=False))\n",
    "\n",
    "# fitting to the full dataset \n",
    "full_gbm_cv_scaled.fit(x_data_scaled, y_data)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # printing the optimal parameters and best score\n",
    "    print(\"Tuned Parameters:\", full_gbm_cv_scaled.best_params_)\n",
    "    print(\"Tuned CV AUC    :\", full_gbm_cv_scaled.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "outdoor-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preventing print output if it is not needed\n",
    "if show_dev_output:\n",
    "    \n",
    "    # best estimators based on RandomizedSearchCV\n",
    "    print(full_gbm_cv_scaled.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "current-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating with best_estimator\n",
    "gbm_tuned_scaled = full_gbm_cv_scaled.best_estimator_\n",
    "\n",
    "# predicting based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_scaled.predict(x_test_scaled)\n",
    "\n",
    "# saving scoring data\n",
    "gb_tuned_scaled_train_score = gbm_tuned_scaled.\\\n",
    "                                    score(x_train_scaled, y_train).round(4)\n",
    "gb_tuned_scaled_test_score = gbm_tuned_scaled.\\\n",
    "                                    score(x_test_scaled, y_test).round(4)\n",
    "gb_tuned_scaled_auc_score = roc_auc_score(y_true=y_test,\n",
    "                                          y_score=gbm_tuned_pred).round(4)\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing scoring data\n",
    "    print('Training ACCURACY:', gb_tuned_scaled_train_score)\n",
    "    print('Testing ACCURACY :', gb_tuned_scaled_test_score)\n",
    "    print('AUC Score        :', gb_tuned_scaled_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "romantic-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned Parameters: {'learning_rate': 0.11, 'max_depth': 3, \n",
    "#                    'max_features': 19, 'n_estimators': 110}\n",
    "# \n",
    "# GradientBoostingClassifier(learning_rate=0.11, max_features=19,\n",
    "#                            n_estimators=110, random_state=219)\n",
    "# \n",
    "# Training ACCURACY: 0.8444\n",
    "# Testing ACCURACY : 0.8501\n",
    "# AUC Score        : 0.7931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "crucial-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking the confusion matrix\n",
    "gb_tuned_tn, \\\n",
    "gb_tuned_fp, \\\n",
    "gb_tuned_fn, \\\n",
    "gb_tuned_tp = confusion_matrix(y_true=y_test, y_pred=gbm_tuned_pred).ravel()\n",
    "\n",
    "# preventing print output if it is not needed\n",
    "if show_intermediate_output:\n",
    "    \n",
    "    # printing each result one-by-one\n",
    "    print(f\"\"\"\n",
    "True Negatives : {gb_tuned_tn}\n",
    "False Positives: {gb_tuned_fp}\n",
    "False Negatives: {gb_tuned_fn}\n",
    "True Positives : {gb_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "proof-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the model\n",
    "\n",
    "# setting threshold\n",
    "threshold = 0.69\n",
    "\n",
    "# calling the function and getting accuracy and auc scores as well as \n",
    "# confusion matrix parameters\n",
    "adj_gbm_train_score, \\\n",
    "adj_gbm_test_score, \\\n",
    "adj_gbm_auc, \\\n",
    "adj_gbm_tn_test, \\\n",
    "adj_gbm_fp_test, \\\n",
    "adj_gbm_fn_test, \\\n",
    "adj_gbm_tp_test = model_adjusting(gbm_tuned_scaled, \n",
    "                                  x_train_scaled, y_train, \n",
    "                                  x_test_scaled, y_test, threshold, \n",
    "                                  print_output=show_intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "preceding-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# printing results ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "binary-imaging",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Model Name            Training Accuracy  Testing Accuracy  AUC Score    Confusion Matrix\n",
      "--------------------------    -----------------  ----------------  ---------    ----------------\n",
      "Logistic Regression                 0.7697            0.7639          0.689    True Negatives : 75\n",
      "                                                                               False Positives: 81\n",
      "                                                                               False Negatives: 34\n",
      "                                                                               True Positives : 297\n",
      "\n",
      "Logistic Regression (tuned)         0.7629            0.7659         0.6922    True Negatives : 76\n",
      "                                                                               False Positives: 80\n",
      "                                                                               False Negatives: 34\n",
      "                                                                               True Positives : 297 \n",
      "\n",
      "Logistic Regression (adjusted)      0.7526            0.7598         0.7277    True Negatives : 121\n",
      "                                                                               False Positives: 35\n",
      "                                                                               False Negatives: 106\n",
      "                                                                               True Positives : 225\n",
      "    \n",
      "Decision Tree (tuned)               0.7224            0.7577         0.7506    True Negatives : 114\n",
      "                                                                               False Positives: 42\n",
      "                                                                               False Negatives: 76\n",
      "                                                                               True Positives : 255\n",
      "\n",
      "Decision Tree (adjusted)            0.9431            0.9446          0.757    True Negatives : 124\n",
      "                                                                               False Positives: 32\n",
      "                                                                               False Negatives: 93\n",
      "                                                                               True Positives : 238\n",
      "    \n",
      "KNN                                 0.7183            0.7228         0.5826    True Negatives : 30\n",
      "                                                                               False Positives: 126\n",
      "                                                                               False Negatives: 9\n",
      "                                                                               True Positives : 322\n",
      "\n",
      "KNN (adjusted)                      0.7176            0.7187         0.6774    True Negatives : 94\n",
      "                                                                               False Positives: 62\n",
      "                                                                               False Negatives: 82\n",
      "                                                                               True Positives : 249\n",
      "\n",
      "Random Forest (adjusted)            0.8533            0.8255         0.6445    True Negatives : 63\n",
      "                                                                               False Positives: 93\n",
      "                                                                               False Negatives: 38\n",
      "                                                                               True Positives : 293\n",
      "\n",
      "GBM (tuned)                         0.8444            0.8501         0.7931    True Negatives : 99\n",
      "                                                                               False Positives: 57\n",
      "                                                                               False Negatives: 16\n",
      "                                                                               True Positives : 315\n",
      "    \n",
      "GBM (adjusted)*                     0.8314            0.8316         0.8438    True Negatives : 136\n",
      "                                                                               False Positives: 20\n",
      "                                                                               False Negatives: 61\n",
      "                                                                               True Positives : 270 \n",
      "\n",
      "\n",
      "* Adjusted Gradient Boosting Model demonstrated the best result.\n",
      "  \n",
      "** Script running time: 103.7 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "# comparing results\n",
    "print(f\"\"\"\n",
    "        Model Name            Training Accuracy  Testing Accuracy  AUC Score    Confusion Matrix\n",
    "--------------------------    -----------------  ----------------  ---------    ----------------\n",
    "Logistic Regression{lr_train_score:>23}{lr_test_score:>18}{lr_auc:>15}{'':>4}True Negatives : {lr_tn}\n",
    "{'':>79}False Positives: {lr_fp}\n",
    "{'':>79}False Negatives: {lr_fn}\n",
    "{'':>79}True Positives : {lr_tp}\n",
    "\n",
    "Logistic Regression (tuned){lr_tuned_train_score:>15}{lr_tuned_test_score:>18}{lr_tuned_auc:>15}{'':>4}True Negatives : {lr_tuned_tn}\n",
    "{'':>79}False Positives: {lr_tuned_fp}\n",
    "{'':>79}False Negatives: {lr_tuned_fn}\n",
    "{'':>79}True Positives : {lr_tuned_tp} \n",
    "\n",
    "Logistic Regression (adjusted){adj_lr_train_score:>12}{adj_lr_test_score:>18}{adj_lr_auc:>15}{'':>4}True Negatives : {adj_lr_tn_test}\n",
    "{'':>79}False Positives: {adj_lr_fp_test}\n",
    "{'':>79}False Negatives: {adj_lr_fn_test}\n",
    "{'':>79}True Positives : {adj_lr_tp_test}\n",
    "    \n",
    "Decision Tree (tuned){dt_tuned_train_score:>21}{dt_tuned_test_score:>18}{dt_tuned_auc:>15}{'':>4}True Negatives : {dt_tuned_tn}\n",
    "{'':>79}False Positives: {dt_tuned_fp}\n",
    "{'':>79}False Negatives: {dt_tuned_fn}\n",
    "{'':>79}True Positives : {dt_tuned_tp}\n",
    "\n",
    "Decision Tree (adjusted){adj_dt_train_score:>18}{adj_dt_test_score:>18}{adj_dt_auc:>15}{'':>4}True Negatives : {adj_dt_tn_test}\n",
    "{'':>79}False Positives: {adj_dt_fp_test}\n",
    "{'':>79}False Negatives: {adj_dt_fn_test}\n",
    "{'':>79}True Positives : {adj_dt_tp_test}\n",
    "    \n",
    "KNN {knn_train_score:>38}{knn_test_score:>18}{knn_auc_score:>15}{'':>4}True Negatives : {knn_tn}\n",
    "{'':>79}False Positives: {knn_fp}\n",
    "{'':>79}False Negatives: {knn_fn}\n",
    "{'':>79}True Positives : {knn_tp}\n",
    "\n",
    "KNN (adjusted){adj_knn_train_score:>28}{adj_knn_test_score:>18}{adj_knn_auc:>15}{'':>4}True Negatives : {adj_knn_tn_test}\n",
    "{'':>79}False Positives: {adj_knn_fp_test}\n",
    "{'':>79}False Negatives: {adj_knn_fn_test}\n",
    "{'':>79}True Positives : {adj_knn_tp_test}\n",
    "\n",
    "Random Forest (adjusted){adj_rf_tuned_train_score:>18}{adj_rf_tuned_test_score:>18}{adj_rf_tuned_auc:>15}{'':>4}True Negatives : {adj_rf_tuned_tn_test}\n",
    "{'':>79}False Positives: {adj_rf_tuned_fp_test}\n",
    "{'':>79}False Negatives: {adj_rf_tuned_fn_test}\n",
    "{'':>79}True Positives : {adj_rf_tuned_tp_test}\n",
    "\n",
    "GBM (tuned) {gb_tuned_scaled_train_score:>30}{gb_tuned_scaled_test_score:>18}{gb_tuned_scaled_auc_score:>15}{'':>4}True Negatives : {gb_tuned_tn}\n",
    "{'':>79}False Positives: {gb_tuned_fp}\n",
    "{'':>79}False Negatives: {gb_tuned_fn}\n",
    "{'':>79}True Positives : {gb_tuned_tp}\n",
    "    \n",
    "GBM (adjusted)* {adj_gbm_train_score:>26}{adj_gbm_test_score:>18}{adj_gbm_auc:>15}{'':>4}True Negatives : {adj_gbm_tn_test}\n",
    "{'':>79}False Positives: {adj_gbm_fp_test}\n",
    "{'':>79}False Negatives: {adj_gbm_fn_test}\n",
    "{'':>79}True Positives : {adj_gbm_tp_test} \n",
    "\n",
    "\n",
    "* Adjusted Gradient Boosting Model demonstrated the best result.\n",
    "  \n",
    "** Script running time: {round((end_time - start_time), 1)} s\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
